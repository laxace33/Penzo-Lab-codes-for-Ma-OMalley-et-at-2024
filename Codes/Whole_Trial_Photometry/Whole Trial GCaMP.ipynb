{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate GCaMP DFF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Read in the autofluorescence, GCaMP, and shock csv files and return auto, gcamp, and shock pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages \n",
    "import os as os #os\n",
    "import pandas as pd #pandas\n",
    "import numpy as np #numpy\n",
    "import scipy as scipy #scipy\n",
    "import matplotlib.lines as mlines #matplotlib\n",
    "import matplotlib.pyplot as plt #matplotlib\n",
    "plt.style.use('ggplot') #emulate ggplot from R\n",
    "#% matplotlib inline \n",
    "#view plots in jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *User Input Required Below*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\\n"
     ]
    }
   ],
   "source": [
    "#***change working directory, ID, session, and number of trials**** \n",
    "#***These are the only details you need to change to run the whole script***\n",
    "\n",
    "#IMPORTANT - to change working directory, use os.chdir(path)\n",
    "os.chdir('C:\\\\')\n",
    "working_directory = os.getcwd() \n",
    "print(working_directory)\n",
    "ID = ''\n",
    "session = ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *User Input Required Below*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the autofluorescence, GCaMP, and cue csv files and return auto, gcamp, and shock pandas DataFrames\n",
    "#IMPORTANT - to change file name, format as ('file name.csv')\n",
    "auto = pd.read_csv(ID + '_' + session +'_AF.csv') \n",
    "gcamp = pd.read_csv(ID + '_' + session + '_GC.csv')\n",
    "shock = pd.read_csv(ID + '_' + session + '_cue.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Combine the time column and the auto, gcamp, and shock d0 columns to create a master pandas DataFrame. Write out the master pandas DataFrame as a csv file to the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make auto, gcamp, and shock column headings lowercase\n",
    "auto.columns = auto.columns.str.lower()\n",
    "gcamp.columns = gcamp.columns.str.lower()\n",
    "shock.columns = shock.columns.str.lower()\n",
    "#absolute value of shock d0 column values\n",
    "shock.d0 = shock.d0.abs()\n",
    "#combine time column and auto, gcamp, and shock d0 columns to create master pandas DataFrame\n",
    "master = pd.concat([auto['time'], auto['d0'], gcamp['d0'], shock['d0']], axis = 1, keys = ['time', 'auto', 'gcamp', 'shock'])\n",
    "#write out master as a csv file to working directory\n",
    "master.to_csv(ID + '_' + session + '_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Determine the data range for the calculations. Create a master_input pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shock_onset_rows = [591, 1055, 1649, 2257, 3496, 3946, 4961, 5912, 6278, 7010, 7652, 8272, 8417, 9141, 9965, 10510, 10666, 11503, 11785, 12158, 12918, 13704, 14390, 15089, 15451, 15877, 16059, 16616, 16755, 17349, 17534, 18136, 18237, 18312, 18948, 19203, 19503, 19641, 19738, 19820, 19870, 20286, 20817, 21124, 21276, 21774, 21942, 22023, 22679, 23411, 24024, 24282, 24532, 24606, 24927, 25748, 25884, 26503, 27161, 27657]\n"
     ]
    }
   ],
   "source": [
    "#determine the rows in which shock occurs\n",
    "shock_rows = master.loc[master.shock > .75].index[:].tolist()\n",
    "#determine the rows in which shock onset occurs\n",
    "shock_onset_rows = [shock_rows[0]]\n",
    "for i in range(1, len(shock_rows)):\n",
    "    if shock_rows[i] > shock_rows[i - 1] + 1: \n",
    "        shock_onset_rows.append(shock_rows[i])\n",
    "\n",
    "file_num = 1 #set file number to start at 1 initially \n",
    "shock_onset_rows = shock_onset_rows[0:len(shock_rows)]\n",
    "print('shock_onset_rows =' , shock_onset_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *User Input Required Below*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shock_onset = 591\n",
      "begin_input = 551\n",
      "end_input = 631\n",
      "shock_onset = 1055\n",
      "begin_input = 1015\n",
      "end_input = 1095\n",
      "shock_onset = 1649\n",
      "begin_input = 1609\n",
      "end_input = 1689\n",
      "shock_onset = 2257\n",
      "begin_input = 2217\n",
      "end_input = 2297\n",
      "shock_onset = 3496\n",
      "begin_input = 3456\n",
      "end_input = 3536\n",
      "shock_onset = 3946\n",
      "begin_input = 3906\n",
      "end_input = 3986\n",
      "shock_onset = 4961\n",
      "begin_input = 4921\n",
      "end_input = 5001\n",
      "shock_onset = 5912\n",
      "begin_input = 5872\n",
      "end_input = 5952\n",
      "shock_onset = 6278\n",
      "begin_input = 6238\n",
      "end_input = 6318\n",
      "shock_onset = 7010\n",
      "begin_input = 6970\n",
      "end_input = 7050\n",
      "shock_onset = 7652\n",
      "begin_input = 7612\n",
      "end_input = 7692\n",
      "shock_onset = 8272\n",
      "begin_input = 8232\n",
      "end_input = 8312\n",
      "shock_onset = 8417\n",
      "begin_input = 8377\n",
      "end_input = 8457\n",
      "shock_onset = 9141\n",
      "begin_input = 9101\n",
      "end_input = 9181\n",
      "shock_onset = 9965\n",
      "begin_input = 9925\n",
      "end_input = 10005\n",
      "shock_onset = 10510\n",
      "begin_input = 10470\n",
      "end_input = 10550\n",
      "shock_onset = 10666\n",
      "begin_input = 10626\n",
      "end_input = 10706\n",
      "shock_onset = 11503\n",
      "begin_input = 11463\n",
      "end_input = 11543\n",
      "shock_onset = 11785\n",
      "begin_input = 11745\n",
      "end_input = 11825\n",
      "shock_onset = 12158\n",
      "begin_input = 12118\n",
      "end_input = 12198\n",
      "shock_onset = 12918\n",
      "begin_input = 12878\n",
      "end_input = 12958\n",
      "shock_onset = 13704\n",
      "begin_input = 13664\n",
      "end_input = 13744\n",
      "shock_onset = 14390\n",
      "begin_input = 14350\n",
      "end_input = 14430\n",
      "shock_onset = 15089\n",
      "begin_input = 15049\n",
      "end_input = 15129\n",
      "shock_onset = 15451\n",
      "begin_input = 15411\n",
      "end_input = 15491\n",
      "shock_onset = 15877\n",
      "begin_input = 15837\n",
      "end_input = 15917\n",
      "shock_onset = 16059\n",
      "begin_input = 16019\n",
      "end_input = 16099\n",
      "shock_onset = 16616\n",
      "begin_input = 16576\n",
      "end_input = 16656\n",
      "shock_onset = 16755\n",
      "begin_input = 16715\n",
      "end_input = 16795\n",
      "shock_onset = 17349\n",
      "begin_input = 17309\n",
      "end_input = 17389\n",
      "shock_onset = 17534\n",
      "begin_input = 17494\n",
      "end_input = 17574\n",
      "shock_onset = 18136\n",
      "begin_input = 18096\n",
      "end_input = 18176\n",
      "shock_onset = 18237\n",
      "begin_input = 18197\n",
      "end_input = 18277\n",
      "shock_onset = 18312\n",
      "begin_input = 18272\n",
      "end_input = 18352\n",
      "shock_onset = 18948\n",
      "begin_input = 18908\n",
      "end_input = 18988\n",
      "shock_onset = 19203\n",
      "begin_input = 19163\n",
      "end_input = 19243\n",
      "shock_onset = 19503\n",
      "begin_input = 19463\n",
      "end_input = 19543\n",
      "shock_onset = 19641\n",
      "begin_input = 19601\n",
      "end_input = 19681\n",
      "shock_onset = 19738\n",
      "begin_input = 19698\n",
      "end_input = 19778\n",
      "shock_onset = 19820\n",
      "begin_input = 19780\n",
      "end_input = 19860\n",
      "shock_onset = 19870\n",
      "begin_input = 19830\n",
      "end_input = 19910\n",
      "shock_onset = 20286\n",
      "begin_input = 20246\n",
      "end_input = 20326\n",
      "shock_onset = 20817\n",
      "begin_input = 20777\n",
      "end_input = 20857\n",
      "shock_onset = 21124\n",
      "begin_input = 21084\n",
      "end_input = 21164\n",
      "shock_onset = 21276\n",
      "begin_input = 21236\n",
      "end_input = 21316\n",
      "shock_onset = 21774\n",
      "begin_input = 21734\n",
      "end_input = 21814\n",
      "shock_onset = 21942\n",
      "begin_input = 21902\n",
      "end_input = 21982\n",
      "shock_onset = 22023\n",
      "begin_input = 21983\n",
      "end_input = 22063\n",
      "shock_onset = 22679\n",
      "begin_input = 22639\n",
      "end_input = 22719\n",
      "shock_onset = 23411\n",
      "begin_input = 23371\n",
      "end_input = 23451\n",
      "shock_onset = 24024\n",
      "begin_input = 23984\n",
      "end_input = 24064\n",
      "shock_onset = 24282\n",
      "begin_input = 24242\n",
      "end_input = 24322\n",
      "shock_onset = 24532\n",
      "begin_input = 24492\n",
      "end_input = 24572\n",
      "shock_onset = 24606\n",
      "begin_input = 24566\n",
      "end_input = 24646\n",
      "shock_onset = 24927\n",
      "begin_input = 24887\n",
      "end_input = 24967\n",
      "shock_onset = 25748\n",
      "begin_input = 25708\n",
      "end_input = 25788\n",
      "shock_onset = 25884\n",
      "begin_input = 25844\n",
      "end_input = 25924\n",
      "shock_onset = 26503\n",
      "begin_input = 26463\n",
      "end_input = 26543\n",
      "shock_onset = 27161\n",
      "begin_input = 27121\n",
      "end_input = 27201\n",
      "shock_onset = 27657\n",
      "begin_input = 27617\n",
      "end_input = 27697\n"
     ]
    }
   ],
   "source": [
    "for num in shock_onset_rows: \n",
    "    #create shock_onset\n",
    "    shock_onset = num #IMPORTANT - can change number to any of the numbers in shock_onset_rows\n",
    "    if shock_onset in shock_onset_rows:\n",
    "        print('shock_onset =', shock_onset)\n",
    "    else:\n",
    "        raise ValueError('shock_onset not found in shock_onset_rows')\n",
    "    #create begin_input \n",
    "    begin_input = shock_onset - 120 #IMPORTANT - can change number to any number of rows before shock onset\n",
    "    print('begin_input =', begin_input)\n",
    "    #create last_row\n",
    "    last_row = len(master) - shock_onset - 1\n",
    "    #create end_inputD7_Ext3_091021_AF\n",
    "    end_input = shock_onset + 240 #IMPORTANT - can change number to any number of rows after shock onset or to last_row for the last row in the data set\n",
    "    print('end_input =', end_input)\n",
    "    #create file name for future files\n",
    "    file_num_str = str(file_num) #change file number to string so it can be added to the file name\n",
    "    file_name = ID + '_' + session + '_Stim_T'+ file_num_str #IMPORTANT - to change file name, format as 'file name8\n",
    "    #create master_input pandas DataFrame\n",
    "    master_input = master[begin_input:end_input + 1]\n",
    "    \n",
    "    ##### 4) Determine auto/gcamp linear trendline equations. Create auto/gcamp scatter plots with auto/gcamp linear trendlines. Save the auto/gcamp plots as PDFs to the working directory.\n",
    "    #create master_trendlines pandas DataFrame\n",
    "    master_trendlines = master_input.loc[begin_input:shock_onset - 1]\n",
    "    #reset master_trendlines row index \n",
    "    master_trendlines = master_trendlines.reset_index(drop = True)\n",
    "    #create x_master_trendlines (ranging from 1 to # rows in master_trendlines) pandas DataFrame\n",
    "    x_range_master_trendlines = master_trendlines.axes[0] - (master_trendlines.axes[0][0] - 1)\n",
    "    x_master_trendlines = pd.DataFrame({'x': x_range_master_trendlines})\n",
    "    #add x_master_trendlines to master_trendlines \n",
    "    master_trendlines = pd.concat([x_master_trendlines, master_trendlines], axis=1, join='inner') \n",
    "    \n",
    "    #determine auto linear trendline equation\n",
    "    from pylab import *\n",
    "    (a, b) = polyfit(master_trendlines.x, master_trendlines.auto, 1)\n",
    "    auto_linear_trendline_equation = 'y = ' + str(round(a, 5)) + 'x + ' + str(round(b, 5))\n",
    "    \n",
    "    #create auto scatter plot with auto linear trendline\n",
    "    plt.scatter(master_trendlines.x, master_trendlines.auto, color = 'blue', s = 10)\n",
    "    auto_trendline_values = polyval([a,b], master_trendlines.x)\n",
    "    plt.plot(master_trendlines.x, auto_trendline_values, linewidth = 3, color = 'red')\n",
    "    plt.title(auto_linear_trendline_equation, fontsize = 10, y = 0.9)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('autofluorescence')\n",
    "    #save auto scatter plot as PDF to working directory\n",
    "    plt.savefig('auto_plot_' + file_name + '.pdf')\n",
    "    \n",
    "    #determine gcamp linear trendline equation\n",
    "    from pylab import *\n",
    "    (c, d) = polyfit(master_trendlines.x, master_trendlines.gcamp, 1)\n",
    "    gcamp_linear_trendline_equation = 'y = ' + str(round(c, 5)) + 'x + ' + str(round(d, 5))\n",
    "    \n",
    "    #create gcamp scatter plot with gcamp linear trendline\n",
    "    plt.scatter(master_trendlines.x, master_trendlines.gcamp, color = 'blue', s = 10)\n",
    "    gcamp_trendline_values = polyval([c,d], master_trendlines.x)\n",
    "    plt.plot(master_trendlines.x, gcamp_trendline_values, linewidth = 3, color = 'red')\n",
    "    plt.title(gcamp_linear_trendline_equation, fontsize = 10, y = 0.9)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('gcamp')\n",
    "    #save gcamp scatter plot as PDF to working directory\n",
    "    plt.savefig('gcamp_plot_' + file_name + '.pdf')\n",
    "    \n",
    "    #create master_calculations pandas DataFrame\n",
    "    master_calculations = master_input\n",
    "    #reset master_calculations row index \n",
    "    master_calculations = master_calculations.reset_index(drop = True)\n",
    "    #create x_master_calculations (ranging from 1 to # rows in master_calculations) pandas DataFrame\n",
    "    x_range_master_calculations = master_calculations.axes[0] - (master_calculations.axes[0][0] - 1)\n",
    "    x_master_calculations = pd.DataFrame({'x': x_range_master_calculations})\n",
    "    #add x_master_calculations to master_calculations \n",
    "    master_calculations = pd.concat([x_master_calculations, master_calculations], axis = 1, join = 'inner')\n",
    "    \n",
    "    #create auto_trendline_y pandas DataFrame \n",
    "    auto_y_list = []\n",
    "    for x in x_range_master_calculations:\n",
    "        y = a*x + b \n",
    "        auto_y_list.append(y)\n",
    "    auto_y_array = np.array(auto_y_list)\n",
    "    auto_trendline_y = pd.DataFrame({'auto_trendline_y': auto_y_array})\n",
    "    #add auto_trendline_y to master_calculations\n",
    "    master_calculations = pd.concat([master_calculations, auto_trendline_y], axis = 1, join = 'inner')\n",
    "    #create gcamp_trendline_y pandas DataFrame\n",
    "    gcamp_y_list = []\n",
    "    for x in x_range_master_calculations:\n",
    "        y = a*x + d \n",
    "        gcamp_y_list.append(y)\n",
    "    gcamp_y_array = np.array(gcamp_y_list)\n",
    "    gcamp_trendline_y = pd.DataFrame({'gcamp_trendline_y': gcamp_y_array})\n",
    "    #add gcamp_trendline_y to master_calculations\n",
    "    master_calculations = pd.concat([master_calculations, gcamp_trendline_y], axis = 1, join = 'inner')\n",
    "    \n",
    "    #subtract auto_trendline_y from auto to create auto_fit column in master_calculations\n",
    "    master_calculations['auto_fit'] = master_calculations['auto'] - master_calculations['auto_trendline_y']\n",
    "    #subtract gcamp_trendline_y from gcamp to create gcamp_fit column in master_calculations\n",
    "    master_calculations['gcamp_fit'] = master_calculations['gcamp'] - master_calculations['gcamp_trendline_y']\n",
    "    \n",
    "    #add gcamp_trendline y-intercept to auto_fit to create auto_fit column in master_calculations\n",
    "    master_calculations['auto_final'] = d + master_calculations['auto_fit']\n",
    "    #add gcamp_trendline y-intercept to gcamp_fit to create gcamp_fit column in master_calculations\n",
    "    master_calculations['gcamp_final'] = d + master_calculations['gcamp_fit']\n",
    "\n",
    "    #calculate delta f/f (dff) and create dff column in master_calculations\n",
    "    master_calculations['dff']= ((master_calculations['gcamp_final'] - master_calculations['auto_final'])/master_calculations['auto_final'])*100\n",
    "    \n",
    "    #write out master_calculations as a csv file to working directory\n",
    "    master_calculations.to_csv('master_calculations_' + file_name + '.csv') \n",
    "    \n",
    "    #determine the rows in which shock occurs\n",
    "    shock_rows_dff = master_calculations.loc[master_calculations.shock < 1].index[:].tolist()\n",
    "    #determine the rows in which shock onset occurs\n",
    "    shock_onset_rows_dff = [shock_rows_dff[0]]\n",
    "    for i in range(2, len(shock_rows_dff)):\n",
    "        if shock_rows_dff[i] > shock_rows_dff[i - 1] + 1: \n",
    "            shock_onset_rows_dff.append(shock_rows_dff[i])\n",
    "    #determine the times in which shock onset occurs\n",
    "    shock_onset_time_dff = list(master_calculations.time.loc[shock_onset_rows_dff])\n",
    "    #create dff line plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(master_calculations.time, master_calculations.dff, color = 'blue')\n",
    "    ax.set_xlabel('time (sec)')\n",
    "    ax.set_ylabel('delta f/f')\n",
    "    x = 0\n",
    "    while x < len(shock_onset_time_dff):\n",
    "        ax.annotate(' ', xy =(shock_onset_time_dff[x], min(master_calculations.dff)), arrowprops = dict(facecolor = 'black', shrink = 0.05))\n",
    "        x = x + 1\n",
    "    arrow = mlines.Line2D([], [], color = 'black', marker = '^', markersize = 12, label = 'cue onset')\n",
    "    ax.legend(handles = [arrow])\n",
    "    #while x < len(shock_onset_time_dff):\n",
    "        #ax.annotate(' ', xy =([shock_onset_time_dff[x] + 30], min(master_calculations.dff)), arrowprops = dict(facecolor = 'yellow', shrink = 0.05))\n",
    "        #x = x + 1\n",
    "    #arrow2 = mlines.Line2D([], [], color = 'yellow', marker = '^', markersize = 12, label = 'cue offset')\n",
    "    #ax.legend(handles = [arrow, arrow2])\n",
    "    #save dff line plot as PDF to working directory\n",
    "    fig.savefig('dff_plot_' + file_name + '.pdf') \n",
    "    \n",
    "    #Necessary for iterative code\n",
    "    matplotlib.pyplot.close('all')\n",
    "    file_num += 1 #increase file number by 1 for next file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenation step \n",
    "#Make sure you have number_trials set to the correct number at the beginning of the script\n",
    "\n",
    "#number_trials = [x+1 for x in range(0,len(shock_rows))] #change range number to reflect your number of trials\n",
    "#print(number_trials)\n",
    "\n",
    "rows = [x+1 for x in range(0,len(shock_onset_rows))] #set at beginning of script\n",
    "file_name = 'master_calculations_' + ID + '_' + session + '_Stim_T' + str(rows[0]) + '.csv' #Changes file name for each animal based on settings at begining\n",
    "\n",
    "df = pd.read_csv(file_name)\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.head(3)\n",
    "\n",
    "total_dff = pd.DataFrame()\n",
    "total_dff[str(rows[0])] = df.dff\n",
    "total_dff.head(3)\n",
    "\n",
    "for row in rows:\n",
    "    file_name = 'master_calculations_' + ID + '_' + session + '_Stim_T' + str(row) + '.csv' #Changes file name for each animal\n",
    "    df = pd.read_csv(file_name)\n",
    "    df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    total_dff[str(row)] = df.dff\n",
    "    \n",
    "total_dff.head(5)\n",
    "\n",
    "total_dff['avg'] = total_dff.mean(axis=1)\n",
    "\n",
    "total_dff.to_csv(ID + '_' + session + '_final.csv') #Save to new file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291.4410305165385\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
